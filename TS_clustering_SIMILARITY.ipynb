{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sktime.clustering.k_means import TimeSeriesKMeans as TSKM\n",
    "from sktime.distances import dtw_distance, pairwise_distance, lcss_distance, wddtw_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicja zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [ \"pcm_LOGenergy_sma\",\n",
    "    \"pcm_zcr_sma\" ,\n",
    "    \"voiceprob_sma\" ,\n",
    "    \"f0_sma\" ,\n",
    "    \"f0env_sma\",\n",
    "    \"pcm_fftMag_fband0-250_sma\" ,\n",
    "    \"pcm_fftMag_fband0-650_sma\",\n",
    "    \"pcm_fftMag_spectralRollOff25_0_sma\" ,\n",
    "    \"pcm_fftMag_spectralRollOff50_0_sma\",\n",
    "    \"pcm_fftMag_spectralRollOff75_0_sma\",\n",
    "    \"pcm_fftMag_spectralRollOff90_0_sma\", \n",
    "    \"pcm_fftmag_spectralflux_sma\",\n",
    "    \"pcm_fftmag_spectralcentroid_sma\" ,\n",
    "    \"pcm_fftmag_spectralmaxpos_sma\" ,\n",
    "    \"pcm_fftmag_spectralminpos_sma\" ,\n",
    "    \"f0final_sma\" ,\n",
    "    \"voicingfinalunclipped_sma\",\n",
    "    \"jitterlocal_sma\",\n",
    "    \"jitterddp_sma\",\n",
    "    \"shimmerlocal_sma\",\n",
    "    \"loghnr_sma\",\n",
    "    \"audspec_lengthl1norm_sma\" ,\n",
    "    \"audspecrasta_lengthl1norm_sma\" ,\n",
    "    \"pcm_rmsenergy_sma\",\n",
    "    \"audSpec_Rfilt_sma_compare_0_\",\n",
    "    \"audSpec_Rfilt_sma_compare_1_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_2_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_3_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_4_\",\n",
    "    \"audSpec_Rfilt_sma_compare_5_\",\n",
    "    \"audSpec_Rfilt_sma_compare_6_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_7_\",\n",
    "    \"audSpec_Rfilt_sma_compare_8_\",\n",
    "    \"audSpec_Rfilt_sma_compare_9_\",\n",
    "    \"audSpec_Rfilt_sma_compare_10_\",\n",
    "    \"audSpec_Rfilt_sma_compare_11_\",\n",
    "    \"audSpec_Rfilt_sma_compare_12_\",\n",
    "    \"audSpec_Rfilt_sma_compare_13_\",\n",
    "    \"audSpec_Rfilt_sma_compare_14_\",\n",
    "    \"audSpec_Rfilt_sma_compare_15_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_16_\",\n",
    "    \"audSpec_Rfilt_sma_compare_17_\",\n",
    "    \"audSpec_Rfilt_sma_compare_18_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_19_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_20_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_21_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_22_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_23_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_24_\" ,\n",
    "    \"audSpec_Rfilt_sma_compare_25_\",\n",
    "    \"pcm_fftMag_fband250-650_sma_compare\" ,\n",
    "    \"pcm_fftMag_fband1000-4000_sma_compare\",\n",
    "    \"pcm_fftmag_spectralentropy_sma_compare\",\n",
    "    \"pcm_fftmag_spectralvariance_sma_compare\" ,\n",
    "    \"pcm_fftmag_spectralskewness_sma_compare\",\n",
    "    \"pcm_fftmag_spectralkurtosis_sma_compare\" ,\n",
    "    \"pcm_fftmag_psysharpness_sma_compare\" ,\n",
    "    \"pcm_fftmag_spectralharmonicity_sma_compare\",\n",
    "    \"loudness_sma3\",\n",
    "    \"alpharatio_sma3\",\n",
    "    \"hammarbergindex_sma3\" ,\n",
    "    \"slope0-500_sma3\" ,\n",
    "    \"slope500-1500_sma3\",\n",
    "    \"F0semitoneFrom27_5Hz_sma3nz\",\n",
    "    \"logRelF0-H1-H2_sma3nz\",\n",
    "    \"logRelF0-H1-A3_sma3nz\" ,\n",
    "    \"f1frequency_sma3nz\" ,\n",
    "    \"f1bandwidth_sma3nz\" ,\n",
    "    \"f1amplitudelogrelf0_sma3nz\" ,\n",
    "    \"f2frequency_sma3nz\" ,\n",
    "    \"f2amplitudelogrelf0_sma3nz\" ,\n",
    "    \"f3frequency_sma3nz\" ,\n",
    "    \"f3amplitudelogrelf0_sma3nz\",\n",
    "    \"pcm_fftMag_mfcc_0_\" ,\n",
    "    \"pcm_fftMag_mfcc_1_\" ,\n",
    "    \"pcm_fftMag_mfcc_2_\" ,\n",
    "    \"pcm_fftMag_mfcc_3_\",\n",
    "    \"pcm_fftMag_mfcc_4_\" ,\n",
    "    \"pcm_fftMag_mfcc_5_\" ,\n",
    "    \"pcm_fftMag_mfcc_6_\",\n",
    "    \"pcm_fftMag_mfcc_7_\",\n",
    "    \"pcm_fftMag_mfcc_8_\",\n",
    "    \"pcm_fftMag_mfcc_9_\",\n",
    "    \"pcm_fftMag_mfcc_10_\",\n",
    "    \"pcm_fftMag_mfcc_11_\",\n",
    "    \"pcm_fftMag_mfcc_12_\"\n",
    "  ]\n",
    "colnames = ['day','hamd_ymrs','patient_id', 'dw_mobilerecording_id', 'frame_nr'] + params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no = 1000\n",
    "cluster_no = 2\n",
    "patient_id = 2582"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie danych dla 1 pacjenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: DO ZASTANOWIENIA SIĘ ILE WYBIERAMY PIERWSZYCH RAMEK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "danonek = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\2582_data.csv\" ) \n",
    "#Wybieram pierwsze 1000 ramek!\n",
    "danonek = danonek.loc[ (danonek.frame_nr <= frame_no) & (danonek.chunk_number == 0), :]\n",
    "danonek_bak = danonek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_v = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\recordings_visits.csv\") \n",
    "rec = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\mobilerecordings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WYbieram dane od 2018 roku\n",
    "rec = rec.loc[rec.create_date >= '2018-01-01',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#połączenie czystego nagrania z datą\n",
    "danonek = pd.merge(danonek, mr_v,  how='left', left_on=['patient_id','dwh_mobilerecording_id'],\n",
    "                    right_on = ['patient_id','dwh_mobilerecording_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [danonek_bak.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficzery = [\n",
    " #'f0_sma',\n",
    "# 'pcm_fftMag_fband0-250_sma',\n",
    "# 'pcm_fftMag_fband0-650_sma',\n",
    " 'f0final_sma',\n",
    "# 'slope0-500_sma3',\n",
    "# 'slope500-1500_sma3',\n",
    " 'f1frequency_sma3nz',\n",
    " 'f2frequency_sma3nz',\n",
    " 'f3frequency_sma3nz',\n",
    " 'pcm_fftMag_mfcc_5_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "description =  ficzery + [ 'dwh_mobilerecording_id', 'frame_nr', 'create_date','hamd_ymrs', 'visit_number', 'hamd_suma', 'yms_suma', 'visit_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "danonek = danonek[description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyznaczenie znanych stanów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visits_no = danonek.visit_number.dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział na dane olabelowane i nieolabelowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [] #zawiera liste tabel oetykietowanych\n",
    "train_sets = [group for _, group in danonek.groupby('visit_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = danonek.loc[danonek.hamd_ymrs.isna(),: ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czyszczenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = danonek.drop_duplicates().reset_index(drop=True).sort_values(['create_date','dwh_mobilerecording_id', 'frame_nr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwam nagrania które nie mają 1000 ramek!!\n",
    "count = all_set['dwh_mobilerecording_id'].value_counts() \n",
    "val_to_remove = count[count < frame_no].index.tolist()\n",
    "all_set = all_set[~all_set['dwh_mobilerecording_id'].isin(val_to_remove)]\n",
    "del(count, val_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [df.drop_duplicates().reset_index(drop=True).sort_values(['dwh_mobilerecording_id', 'frame_nr']) \n",
    "    for df in train_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwam nagrania które nie mają 1000 ramek!!\n",
    "\n",
    "for i in range(len(train_sets)):\n",
    "    df = train_sets[i]\n",
    "    count = df['dwh_mobilerecording_id'].value_counts() \n",
    "    val_to_remove = count[count < frame_no].index.tolist()\n",
    "    train_sets[i] = df[~df['dwh_mobilerecording_id'].isin(val_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.drop_duplicates().reset_index(drop=True).sort_values(['dwh_mobilerecording_id', 'frame_nr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwam nagrania które nie mają 1000 ramek!!\n",
    "count = test_set['dwh_mobilerecording_id'].value_counts() \n",
    "val_to_remove = count[count < frame_no].index.tolist()\n",
    "test_set = test_set[~test_set['dwh_mobilerecording_id'].isin(val_to_remove)]\n",
    "del(count, val_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_ficzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_bak = df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-06\n",
      "2018-03-20\n",
      "2018-03-21\n",
      "2018-03-22\n",
      "2018-03-23\n",
      "2018-03-24\n",
      "2018-03-25\n",
      "2018-03-26\n",
      "2018-03-28\n",
      "2018-03-29\n",
      "2018-03-30\n",
      "2018-03-31\n",
      "2018-04-01\n",
      "2018-04-03\n",
      "2018-04-05\n",
      "2018-04-06\n",
      "2018-04-07\n",
      "2018-04-08\n",
      "2018-04-09\n",
      "2018-04-10\n",
      "2018-04-12\n",
      "2018-04-13\n",
      "2018-04-14\n",
      "2018-04-15\n",
      "2018-04-16\n",
      "2018-04-17\n",
      "2018-04-18\n",
      "2018-04-19\n",
      "2018-04-20\n",
      "2018-04-21\n",
      "2018-04-22\n",
      "2018-04-23\n",
      "2018-04-24\n",
      "2018-04-25\n",
      "2018-04-26\n",
      "2018-04-27\n",
      "2018-04-28\n",
      "2018-04-30\n",
      "2018-05-01\n",
      "2018-05-02\n",
      "2018-05-03\n",
      "2018-05-04\n",
      "2018-05-05\n",
      "2018-05-07\n",
      "2018-05-08\n",
      "2018-05-09\n",
      "2018-05-10\n",
      "2018-05-11\n",
      "2018-05-12\n",
      "2018-05-13\n",
      "2018-06-03\n",
      "2018-06-04\n",
      "2018-06-05\n",
      "2018-06-06\n",
      "2018-06-07\n",
      "2018-06-08\n",
      "2018-06-09\n",
      "2018-06-10\n",
      "2018-06-11\n",
      "2018-06-12\n",
      "2018-06-13\n",
      "2018-06-14\n",
      "2018-06-15\n",
      "2018-06-16\n",
      "2018-06-17\n",
      "2018-06-18\n",
      "2018-06-19\n",
      "2018-06-20\n"
     ]
    }
   ],
   "source": [
    "#dla każdego dnia badania robie clustering na wszystkich parametrach!!!!\n",
    "# a później dopiero porównuje czy to był dzień etykietowany czy nie!!!!\n",
    "\n",
    "days = list(all_set.create_date.unique())\n",
    "\n",
    "km = TSKM(n_clusters=cluster_no,\n",
    "                  metric = 'dtw') # co to:  ‘ddtw’, ‘wdtw’, ‘wddtw’ <- do sprawdzenia\n",
    "\n",
    "\n",
    "rejected_rec = []\n",
    "df_output = pd.DataFrame(columns=['create_date','patient','feature','yms_suma','hamd_suma','hamd_ymrs',\n",
    "                                  'visit_number','visit_day', 'dtw', 'wddtw', \n",
    "                                  'cl0_ile', 'cl1_ile', 'ile_nagran'])\n",
    "\n",
    "for d in days:\n",
    "    print(d)\n",
    "    for param in ficzery:\n",
    "        ts_list = all_set.loc[all_set.create_date == d,:].groupby('dwh_mobilerecording_id')[param].apply(list).reset_index(drop=True)\n",
    "        if(len(ts_list)<2): #jeśli mieliśmy tylko jedno nagranie w 1 dniu to odrzucamy\n",
    "            rejected_rec.append(d)\n",
    "            continue\n",
    "        ts_ficzer = to_time_series_dataset(ts_list)\n",
    "        ts_ficzer = TimeSeriesScalerMinMax().fit_transform(ts_ficzer)\n",
    "        km.fit(ts_ficzer)\n",
    "        #clusters_centers = km.cluster_centers_\n",
    "        #clusters_labels = km.labels_\n",
    "        dtw = dtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel()  )\n",
    "        wddtw = wddtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel()  )\n",
    "\n",
    "        new_row = pd.DataFrame({'create_date' : [d],\n",
    "                                'patient' : [patient_id],\n",
    "                                'feature' : [param],\n",
    "                                'yms_suma' : [all_set.loc[all_set.create_date == d,'yms_suma'].unique()[0]],\n",
    "                                'hamd_suma' :  [all_set.loc[all_set.create_date == d,'hamd_suma'].unique()[0]],\n",
    "                                'hamd_ymrs' :  [all_set.loc[all_set.create_date == d,'hamd_ymrs'].unique()[0]], \n",
    "                                'visit_number' :  [all_set.loc[all_set.create_date == d,'visit_number'].unique()[0]],\n",
    "                                'visit_day' :  [all_set.loc[all_set.create_date == d,'visit_day'].unique()[0]],\n",
    "                            'dtw' : [ dtw],\n",
    "                            'wddtw' : [wddtw],\n",
    "                            'cl0_ile' :   [np.sum(km.labels_ == 0)],\n",
    "                            'cl1_ile'  : [np.sum(km.labels_ == 1)],\n",
    "                            'ile_nagran' : [len(ts_ficzer)]\n",
    "                            })\n",
    "        df_output  = pd.concat([df_output , new_row], ignore_index=True)\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "#30 min!\n",
    "##############################################################################################################\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykres dla zbioru treningowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# def plot_lines(data_list):\n",
    "#     # Create a new figure and axis\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     # Plot lines for each element of the list\n",
    "#     for i in range(5):#range(len(data_list)):\n",
    "#         series = data_list[i]\n",
    "#         x = series.index\n",
    "#         y = series.f1frequency_sma3nz\n",
    "#         ax.plot(x, y, label= series.dwh_mobilerecording_id.unique())\n",
    "\n",
    "#     # Set labels and title\n",
    "#     ax.set_xlabel('X-axis')\n",
    "#     ax.set_ylabel('Y-axis')\n",
    "#     ax.set_title('Lines for List of Series')\n",
    "\n",
    "#     # Add a legend\n",
    "#     ax.legend(alignment = 'right')\n",
    "\n",
    "#     # Display the plot\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot_lines(train_data)\n",
    "# plot_lines(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykres dla zbioru testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# def plot_lines(data_list):\n",
    "#     # Create a new figure and axis\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     # Plot lines for each element of the list\n",
    "#     for i in range(10):#range(len(data_list)):\n",
    "#         series = data_list[i]\n",
    "#         x = series.index\n",
    "#         y = series.f1frequency_sma3nz\n",
    "#         ax.plot(x, y, label= series.dwh_mobilerecording_id.unique())\n",
    "\n",
    "#     # Set labels and title\n",
    "#     ax.set_xlabel('X-axis')\n",
    "#     ax.set_ylabel('Y-axis')\n",
    "#     ax.set_title('Lines for List of Series')\n",
    "\n",
    "#     # Add a legend\n",
    "#     ax.legend(alignment = 'right')\n",
    "\n",
    "#     # Display the plot\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot_lines(dane_danonek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dan_p['create_date'] = pd.to_datetime(dan_p['create_date_x'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# for yi in range(liczba_klastrow):\n",
    "#     plt.subplot(liczba_klastrow, liczba_klastrow)\n",
    "#     for rec in x_train_tes :\n",
    "#         plt.plot(rec.ravel(), \"k-\", alpha=.2)\n",
    "#     plt.plot(model3.cluster_centers_[yi].ravel(), \"r-\")\n",
    "#     plt.xlim(0, sz)\n",
    "#     plt.ylim(-4, 4)\n",
    "#     plt.text(0.55, 0.85,'Cluster %d' % (yi + 1))\n",
    "\n",
    "\n",
    "i=0\n",
    "l = 0\n",
    "for rec in x_train_ts :\n",
    "    if(labelki_klastrow[i] == 0):\n",
    "        plt.plot(rec.ravel(), color='green')\n",
    "        l=l+1\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(centrum_klastrow[0].ravel(),color='red'  )\n",
    "plt.plot(centrum_klastrow[1].ravel(),color='blue'  )\n",
    "plt.title(\"Cluster 1\")\n",
    "print(i)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "k=0\n",
    "for rec in x_train_ts :\n",
    "    if(labelki_klastrow[j] == 1):\n",
    "        plt.plot(rec.ravel(), color='green')\n",
    "        k=k+1\n",
    "    j=j+1\n",
    "plt.title(\"Cluster 2\")\n",
    "plt.plot(centrum_klastrow[1].ravel(),color='red'  )\n",
    "print(j)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dni_no_label = danonek_nolabel_param1.create_date.unique()\n",
    "# for day in dni_no_label:\n",
    "#     day_one = danonek_nolabel_param1.loc[danonek_nolabel_param1.create_date == day, :]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście per dzień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danonek_label_all = danonek.loc[ ~danonek.hamd_ymrs.isnull(),: ]\n",
    "danonek_label_param1_all = danonek_label_all[ ['f1frequency_sma3nz', 'dwh_mobilerecording_id', 'frame_nr', 'create_date','hamd_ymrs']].drop_duplicates().reset_index(drop=True).sort_values(['dwh_mobilerecording_id', 'frame_nr'])\n",
    "#danonek_label_param1_all\n",
    "\n",
    "recordings_label_all = danonek_label_param1_all.dwh_mobilerecording_id.unique()\n",
    "recordings_label_all\n",
    "train_data100x = []\n",
    "\n",
    "for i in recordings_label_all:\n",
    "        n_frames = len(danonek_label_param1_all.loc[danonek_label_param1_all.dwh_mobilerecording_id == i, ['f1frequency_sma3nz']].reset_index(drop=True))\n",
    "        if(n_frames <= 100): #jeśli nagranie ma mniej niż 100 ramek to nie bierzemy go pod uwagę\n",
    "                print(i)\n",
    "                print(n_frames)\n",
    "                continue\n",
    "        train_data100x.append(danonek_label_param1_all.loc[danonek_label_param1_all.dwh_mobilerecording_id == i,\n",
    "         ['dwh_mobilerecording_id','f1frequency_sma3nz','create_date', 'hamd_ymrs']].reset_index(drop=True).head(100)) #wybieram pozostałe informacje dla każdego nagrania\n",
    "\n",
    "#wybieram pierwsze 100 ramek z każdego nagrania\n",
    "#train_data100 = [df.head(100) for df in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data100x)#[12]\n",
    "train_data100x[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liczba_klastrow = 2\n",
    "km = TSKM(n_clusters=liczba_klastrow,\n",
    "                  metric = 'dtw')\n",
    "\n",
    "combined_df_train = pd.concat(train_data100x)\n",
    "# Group the combined DataFrame by the 'date' column\n",
    "grouped_train = combined_df_train.groupby('create_date')\n",
    "\n",
    "#train_frames = []\n",
    "#train_x2 = []\n",
    "centrum_klastrow_list_train = []\n",
    "recs_in_day_train = []\n",
    "\n",
    "df_output_train = pd.DataFrame(columns=['create_date', 'dtw', 'wddtw', \n",
    "                                  'cl0_ile', 'cl1_ile', 'ile_nagran'])\n",
    "\n",
    "# Iterate over the groups\n",
    "for date, group in grouped_train:\n",
    "    # Create a new DataFrame for each unique date\n",
    "    unique_date_df_train = pd.DataFrame(group)\n",
    "\n",
    "    grouped_by_id  = unique_date_df_train.groupby('dwh_mobilerecording_id')\n",
    "    print(date)\n",
    "    lista_dzien = []\n",
    "    for recording_id, sub_group in grouped_by_id:\n",
    "        frequency_values = sub_group['f1frequency_sma3nz'].tolist()\n",
    "        lista_dzien.append(frequency_values)\n",
    "        ficzur = to_time_series_dataset( lista_dzien )\n",
    "        \n",
    "    if (len(ficzur) < 2 ): #jeśli jest tylko 1 nagranie\n",
    "        continue\n",
    "    print(len(ficzur))\n",
    "    ficzur = TimeSeriesScalerMinMax().fit_transform(ficzur )\n",
    "    km.fit(ficzur)\n",
    "    centrum_klastrow_list_train.append(km.cluster_centers_)\n",
    "    \n",
    "    new_row = pd.DataFrame({'create_date' : [date],\n",
    "                            'dtw' : [dtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel())],\n",
    "                            'wddtw' : [wddtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel())],\n",
    "                            'cl0_ile' :   [np.sum(km.labels_ == 0)],\n",
    "                            'cl1_ile'  : [np.sum(km.labels_ == 1)],\n",
    "                            'ile_nagran' : [len(ficzur)]\n",
    "                            })\n",
    "    df_output_train = pd.concat([df_output_train, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# TUTAJ SKOŃCZYŁAM <3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvv_basic = mr_v.loc[(~mr_v.hamd_ymrs.isnull() ) & (mr_v.patient_id == 2582) ,['create_date','hamd_ymrs','visit_day','patient_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_output_train.join(mr_v.loc[~mr_v.hamd_ymrs.isnull(),['create_date','hamd_ymrs']].drop_duplicates(),how='left',on='create_date')\n",
    "vvv_basic = mr_v.loc[(~mr_v.hamd_ymrs.isnull() ) & (mr_v.patient_id == 2582) ,['create_date','hamd_ymrs','visit_day','patient_id']].drop_duplicates()\n",
    "idx = vvv_basic.groupby('create_date')['visit_day'].apply(lambda x: x.abs().idxmin())\n",
    "\n",
    "# Use the index to filter the original DataFrame\n",
    "vvv = vvv_basic.loc[idx]\n",
    "vvv\n",
    "ramka_trainn = pd.merge(df_output_train, vvv , how= 'inner' , on = 'create_date')\n",
    "ramka_trainn.loc[ramka_trainn.visit_day.isin([0,1,-1,-2,-3]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([8.68,2.69,7.14,2.73])\n",
    "np.std([1.78,1,1.37,2.03,1.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_v.loc[~mr_v.hamd_ymrs.isnull(),['create_date','hamd_ymrs']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównywanie danych nieotykietowanych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recordings_nolabel = danonek_nolabel_param1.dwh_mobilerecording_id.unique()\n",
    "test_x = []\n",
    "test_y = []\n",
    "test_data = []\n",
    "\n",
    "for i in recordings_nolabel:\n",
    "        n_frames = len(danonek_nolabel_param1.loc[danonek_nolabel_param1.dwh_mobilerecording_id == i, ['f1frequency_sma3nz']].reset_index(drop=True))\n",
    "        if(n_frames < 100): #jeśli nagranie ma mniej niż 100 ramek to nie bierzemy go pod uwagę\n",
    "                print(i)\n",
    "                print(n_frames)\n",
    "                continue\n",
    "        test_x.append(danonek_nolabel_param1.loc[danonek_nolabel_param1.dwh_mobilerecording_id == i,\n",
    "         ['f1frequency_sma3nz']].reset_index(drop=True).values[0:100]) #wybieram tylko wartości parametru 1\n",
    "        test_y.append(danonek_nolabel_param1.loc[danonek_nolabel_param1.dwh_mobilerecording_id == i,\n",
    "         'hamd_ymrs'].drop_duplicates().reset_index(drop=True)) #wybieram etykiete dla każdego nagrania \n",
    "        test_data.append(danonek_nolabel_param1.loc[danonek_nolabel_param1.dwh_mobilerecording_id == i,\n",
    "         ['dwh_mobilerecording_id','f1frequency_sma3nz','create_date', 'hamd_ymrs']].reset_index(drop=True)) #wybieram pozostałe informacje dla każdego nagrania\n",
    "        \n",
    "\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "x_test_ts = to_time_series_dataset( test_x ) #lista 1447 nagrań po 100 wartości\n",
    "\n",
    "y_test_ts =  test_y\n",
    "x_test_ts = TimeSeriesScalerMinMax().fit_transform(x_test_ts )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test_ts.shape\n",
    "\n",
    "# Check for NaN values\n",
    "nan_indices = np.isnan(x_test_ts)\n",
    "\n",
    "# Get the indices of NaN values using np.where\n",
    "nan_indices = np.where(nan_indices)\n",
    "\n",
    "# Print the indices of NaN values\n",
    "for i, j, k in zip(*nan_indices):\n",
    "    print(f\"NaN value found at index ({i}, {j}, {k})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liczba_klastrow = 2\n",
    "km = TSKM(n_clusters=liczba_klastrow,\n",
    "                  metric = 'dtw')  # co to:  ‘ddtw’, ‘wdtw’, ‘wddtw’ <- do sprawdzenia\n",
    "km.fit(x_test_ts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrum_klastrow = km.cluster_centers_\n",
    "labelki_klastrow = km.labels_\n",
    "inertia = km.inertia_\n",
    "it = km.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wybieram pierwsze 100 ramek z każdego nagrania\n",
    "test_data100 = [df.head(100) for df in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "liczba_klastrow = 2\n",
    "km = TSKM(n_clusters=liczba_klastrow,\n",
    "                  metric = 'dtw')\n",
    "\n",
    "combined_df = pd.concat(test_data100)\n",
    "# Group the combined DataFrame by the 'date' column\n",
    "grouped = combined_df.groupby('create_date')\n",
    "\n",
    "test_frames = []\n",
    "test_x2 = []\n",
    "centrum_klastrow_list = []\n",
    "recs_in_day = []\n",
    "\n",
    "df_output = pd.DataFrame(columns=['create_date', 'dtw', 'wddtw', \n",
    "                                  'cl0_ile', 'cl1_ile', 'ile_nagran'])\n",
    "\n",
    "# Iterate over the groups\n",
    "for date, group in grouped:\n",
    "    # Create a new DataFrame for each unique date\n",
    "    unique_date_df = pd.DataFrame(group)\n",
    "\n",
    "    grouped_by_id  = unique_date_df.groupby('dwh_mobilerecording_id')\n",
    "    print(date)\n",
    "    lista_dzien = []\n",
    "    for recording_id, sub_group in grouped_by_id:\n",
    "        frequency_values = sub_group['f1frequency_sma3nz'].tolist()\n",
    "        lista_dzien.append(frequency_values)\n",
    "        ficzur = to_time_series_dataset( lista_dzien )\n",
    "        \n",
    "    if (len(ficzur) < 2 ): #jeśli jest tylko 1 nagranie\n",
    "        continue\n",
    "    print(len(ficzur))\n",
    "    ficzur = TimeSeriesScalerMinMax().fit_transform(ficzur )\n",
    "    km.fit(ficzur)\n",
    "    centrum_klastrow_list.append(km.cluster_centers_)\n",
    "    \n",
    "    new_row = pd.DataFrame({'create_date' : [date],\n",
    "                            'dtw' : [dtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel())],\n",
    "                            'wddtw' : [wddtw_distance(km.cluster_centers_[0].ravel(), km.cluster_centers_[1].ravel())],\n",
    "                            'cl0_ile' :   [np.sum(km.labels_ == 0)],\n",
    "                            'cl1_ile'  : [np.sum(km.labels_ == 1)],\n",
    "                            'ile_nagran' : [len(ficzur)]\n",
    "                            })\n",
    "    df_output = pd.concat([df_output, new_row], ignore_index=True)\n",
    "\n",
    "    #if date == '2018-03-22':\n",
    "    #    break\n",
    "\n",
    "# TUTAJ SKOŃCZYŁAM <3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "l = 0\n",
    "for rec in x_test_ts :\n",
    "    if(labelki_klastrow[i] == 0):\n",
    "        plt.plot(rec.ravel(), color='green')\n",
    "        l=l+1\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(centrum_klastrow[0].ravel(),color='red'  )\n",
    "plt.title(\"Cluster 1\")\n",
    "print(i)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "k=0\n",
    "for rec in x_test_ts :\n",
    "    if(labelki_klastrow[j] == 1):\n",
    "        plt.plot(rec.ravel(), color='green')\n",
    "        k=k+1\n",
    "    j=j+1\n",
    "plt.title(\"Cluster 2\")\n",
    "plt.plot(centrum_klastrow[1].ravel(),color='red'  )\n",
    "print(j)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.distances import dtw_distance, pairwise_distance, lcss_distance, wddtw_distance\n",
    "\n",
    "#wddtw_distance(centrum_klastrow[0].ravel(), centrum_klastrow[1].ravel()  )\n",
    "dtw_distance(centrum_klastrow[0].ravel(), centrum_klastrow[1].ravel()  )\n",
    "#wddtw_distance(x_train_ts[1:10,1], x_train_ts[51:60,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ea266b9a32e539376479ecefb4b43de94cddfc186952a2290bc119c664ac37e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
